<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Bridging the Gap Between Image Content and Product Intelligence | Vineeth Veetil </title> <meta name="author" content="Vineeth Veetil"> <meta name="description" content="DeepView.ai has developed a cutting-edge fashion search technology that addresses the disconnect between image content and product intelligence in the e-commerce industry"> <meta name="keywords" content="llm, ai, generative-ai, deep-learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://veetil314.github.io/projects/5_project/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Vineeth</span> Veetil </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/projects/">projects</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Bridging the Gap Between Image Content and Product Intelligence</h1> <p class="post-description">DeepView.ai has developed a cutting-edge fashion search technology that addresses the disconnect between image content and product intelligence in the e-commerce industry</p> </header> <article> <h1 id="bridging-the-gap-between-image-content-and-product-intelligence-deepviewais-fashion-search-technology">Bridging the Gap Between Image Content and Product Intelligence: DeepView.ai’s Fashion Search Technology</h1> <h2 id="executive-summary">Executive Summary</h2> <p>DeepView.ai has developed a cutting-edge fashion search technology that addresses the disconnect between image content and product intelligence in the e-commerce industry. By leveraging advanced deep learning image recognition, DeepView.ai enables retailers to enhance product discovery on websites, apps, and social media platforms. This innovative solution has proven to increase conversions by up to 15% within just three weeks of deployment.</p> <h2 id="introduction">Introduction</h2> <p>Search technology has made significant advancements, with users expecting near-perfect results. However, the e-commerce industry still faces challenges in providing relevant and comprehensive search results, particularly in the fashion domain. Retailers struggle to accurately annotate products with relevant keywords, leading to user frustration and suboptimal search experiences.</p> <h2 id="the-problem">The Problem</h2> <p>Fashion shoppers often have a specific look or style in mind when searching online. They translate this desired look into words and attempt to find relevant products on retail websites. However, two key challenges arise:</p> <ol> <li>Translating the desired look into appropriate search terms can be difficult, as many patterns and styles lack clear names.</li> <li>Products must be properly annotated with the words used by the user to appear in search results. Inaccurate or incomplete annotations lead to irrelevant or scarce search results.</li> </ol> <h2 id="deepviewais-solution">DeepView.ai’s Solution</h2> <p>DeepView.ai addresses these challenges by leveraging advanced deep learning image recognition. The AI-powered solution enables retailers to:</p> <ol> <li> <p><strong>Index products with automatic, image-based SMART METADATA</strong>: DeepView.ai’s technology reduces the effort required for manual tagging by 80% and improves search results for underserved queries by 5x.</p> </li> <li> <p><strong>Increase click-through rates on recommended products</strong>: Visual image search enhances product recommendations, leading to higher click-through rates, even for out-of-stock products.</p> </li> <li> <p><strong>Make user-generated and social media images automatically shoppable</strong>: By matching user-generated content (UGC) and social media images with similar products in the online store, DeepView.ai enables retailers to capitalize on the power of visual content.</p> </li> <li> <p><strong>Generate automatic hashtags for social media images and improve SEO</strong>: DeepView.ai’s technology automatically generates relevant hashtags for social media images, enhancing discoverability and improving search engine optimization (SEO).</p> </li> </ol> <h2 id="technology">Technology</h2> <hr> <h3 id="data-collection">Data Collection</h3> <p>Limited video data was obtained from clients for training, which we supplemented with data extracted from various public sources. Our team curated and extracted web video data. Street style images are very difficult to train on due to various conditions:</p> <ol> <li> <p><strong>Pose Variations</strong>: Wearers may be in different poses, such as sitting or standing. Clothing may not be worn and could be shown as folded or hanging from a wardrobe. These pose variations introduce complexity in recognizing fashion items accurately.</p> </li> <li> <p><strong>Occlusion</strong>: Cluttered backgrounds and partial occlusion of fashion items are common in street style images. This makes it challenging for the model to identify and isolate the relevant fashion elements.</p> </li> <li> <p><strong>Lighting Conditions</strong>: Fashion is highly sensitive to lighting. Color pixels can change substantially under different lighting conditions, making it difficult for algorithms to identify the actual color of the item.</p> </li> <li> <p><strong>Attribute Sensitivity</strong>: Fashion search involves multiple attributes that need to match. For example, when searching for a mini dress, users may be looking for specific characteristics such as the shape (e.g., bodycon), sleeve length (e.g., sleeveless, half sleeve, or full sleeve), neckline (e.g., sweetheart, round, or V-neckline), pattern, color, etc. Matching these attributes accurately is crucial for providing relevant search results. We found that learning a taxonomy of fashion attributes was critical for obtaining the best results, in addition to labeled pairs or triplets, for learning the optimal embeddings.</p> </li> </ol> <p>To address these challenges, we employed various techniques during data collection and preprocessing, such as data augmentation, image normalization, and attribute-specific data generation.</p> <h3 id="data-annotation">Data Annotation</h3> <p>We recruited an in-house team of annotators for this project. Developing clear guidelines for the team proved challenging, necessitating an iterative process that included an evaluation phase. During this phase, we continuously refined the guidelines. Annotators were only approved for production annotation after achieving satisfactory accuracy levels in the evaluation phase.</p> <p>Annotation requirements were extensive. The work encompassed various models, including fashion item detection and classification of various attributes. The diversity of data was also critical. Data was categorized based on various sources to ensure diversity at every level. For instance, stock videos are generally cleaner, whereas YouTube videos are noisier. Longer videos were not overrepresented to avoid repetitive occurrences of similar images within the dataset.</p> <p>At that time, there were no suitable annotation tools available, so we built our own in-house tagging tool. This tool was hosted on AWS, providing a scalable and accessible platform for our annotation team.</p> <h3 id="active-learning">Active Learning</h3> <p>First, a baseline model was trained purely based on taxonomy. The model parameters were leveraged to initialize a network to generate embeddings, optimized using a triplet loss function. Then, hard positive and negative triplets were generated iteratively. These triplets were manually tagged by annotators and fed back into the system. This approach greatly sped up the annotation process and improved the model’s performance.</p> <h3 id="image-augmentation">Image Augmentation</h3> <p>To address the need to handle various technical challenges, including clutter, occlusion, diverse lighting &amp; camera angles, and diversity of clothing, we performed extensive data augmentation. This involved applying techniques such as random cropping, flipping, rotation, and color jittering to the images. Data augmentation helped in increasing the variability and robustness of the training data, enabling the model to learn more generalized features.</p> <h3 id="model-development">Model Development</h3> <ol> <li> <p><strong>Object Detection</strong>: Accurate object detection was critical for fashion search. We trained separate detectors for major categories such as tops, skirts, dresses, outerwear, etc. These categories had enough shape differences to warrant separate detectors, improving the overall accuracy of the system.</p> </li> <li> <p><strong>Siamese Architecture</strong>: Initially, we experimented with a Siamese architecture for fashion similarity matching. However, this approach did not produce sufficiently accurate results. We realized that fashion similarity required a more nuanced understanding of various attributes.</p> </li> <li> <p><strong>Triplet Loss</strong>: We found that using triplet loss worked better for fashion similarity matching. Triplet loss allows the model to learn a metric space where similar fashion items are closer together, and dissimilar items are farther apart. This approach improved the model’s ability to match fashion items accurately.</p> </li> <li> <p><strong>Joint Training</strong>: To further enhance the accuracy of the fashion search model, we jointly trained classifiers for various attributes alongside the triplet loss minimization. This approach allowed the model to learn both the attribute-specific features and the overall similarity metric simultaneously.</p> </li> <li> <p><strong>Rich Taxonomy</strong>: We utilized a rich taxonomy of fashion objects to capture the diverse characteristics of fashion items. This taxonomy included up to a hundred different attributes, such as :</p> <ul> <li>Sleeve length: sleeveless, half sleeve, ¾ sleeve, full sleeve</li> <li>Neckline: round neck, cowl neck, V-neck, sweetheart neckline</li> <li>Pattern: jacquard, paisley, and more</li> <li>Shape: bodycon dress, sheath dress, shift dress, A-line dress, and similar categories for skirts, tops, etc.</li> </ul> </li> </ol> <p>The combination of attribute-specific features and the overall similarity metric allowed the model to understand the nuances of fashion and provide highly relevant search results.</p> <p>In short, the development of our fashion search technology involved extensive data collection, annotation, active learning, image augmentation, and iterative model development. By addressing the unique challenges posed by street style images and leveraging advanced techniques such as triplet loss and joint training, we were able to create a highly accurate and efficient fashion search system.</p> <h2 id="schematic-for-e-commerce-integration">Schematic for E-commerce Integration</h2> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/fash-search-deploy-480.webp 480w,/assets/img/fash-search-deploy-800.webp 800w,/assets/img/fash-search-deploy-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/fash-search-deploy.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Figure 1. Vanishing points from different groups of parallel lines form the vanishing line </div> <h2 id="differentiating-factors">Differentiating Factors</h2> <p>DeepView.ai’s solution stood out from competitors in two key aspects:</p> <ol> <li> <p><strong>Natural image compatibility</strong>: The technology works seamlessly with natural images, social media content, and UGC, unlike most image recognition APIs that struggle with noisy or non-professional images.</p> </li> <li> <p><strong>Product-specific feature generation</strong>: DeepView.ai’s system additionally generated product-specific attributes based on images, which is critical for product discovery through keyword search, as well as SEO optimization.</p> </li> </ol> <h2 id="demos">Demos</h2> <p>Demo videos To showcase the capabilities of DeepView.ai’s fashion search technology :</p> <ul> <li><a href="https://www.youtube.com/watch?v=P2nkm4QQ4OM" rel="external nofollow noopener" target="_blank">Demo 1</a></li> <li><a href="https://www.youtube.com/watch?v=q4-2MX2ijJE" rel="external nofollow noopener" target="_blank">Demo 2</a></li> </ul> <h2 id="conclusion">Conclusion</h2> <p>DeepView.ai’s fashion search technology helps advance the e-commerce industry by bridging the gap between image content and product intelligence. By leveraging advanced deep learning image recognition, retailers are able to significantly enhance product discovery, increase conversions, and improve the overall user experience.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Vineeth Veetil. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>